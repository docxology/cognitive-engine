import os
import json
import time
import argparse
import requests
from datetime import datetime
import logging
import glob
from run_pipeline import log_file_operation

def setup_logging():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    logger = logging.getLogger('')
    logger.handlers = [console_handler]
    return logger

logger = setup_logging()

# Specify target System prompt by short name
TARGET_SYSTEM_PROMPT = "ecological_regeneration_planner"

def load_api_key(key_file_path):
    try:
        with open(key_file_path, 'r') as key_file:
            keys = key_file.read().strip().split('\n')
            api_keys = dict(key.split('=') for key in keys)
            perplexity_api_key = api_keys.get('PERPLEXITY_API_KEY')
        
        if not perplexity_api_key:
            raise ValueError("PERPLEXITY_API_KEY not found in the key file")
        
        logger.info("Perplexity API Key loaded successfully")
        return perplexity_api_key
    except Exception as e:
        logger.error(f"Error reading API key: {str(e)}")
        raise

def load_json_file(file_path):
    try:
        with open(file_path, "r", encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Error loading {file_path}: {e}")
        raise

def get_system_message(system_prompts, short_name):
    logger.debug(f"Looking for system prompt with short_name: '{short_name}'")
    logger.debug(f"Available system prompts: {[p.get('short_name', 'UNKNOWN') for p in system_prompts.values() if isinstance(p, dict)]}")
    
    # If the ecological_regeneration_planner prompt doesn't exist, use a default prompt
    if short_name == "ecological_regeneration_planner" and not any(p.get("short_name") == short_name for p in system_prompts.values() if isinstance(p, dict)):
        logger.info(f"Using default ecological regeneration planner prompt since '{short_name}' was not found")
        return {
            "role": "system",
            "content": """You are an expert ecological regeneration planner specializing in developing place-based ecological restoration and regeneration projects. 
Your task is to analyze comprehensive research data for specific bioregions and create detailed, actionable ecological regeneration project plans.

Your plans should:
1. Identify key ecosystems, species, and natural processes that need protection or restoration
2. Highlight local stakeholders, communities, and organizations that should be involved
3. Detail specific ecological regeneration activities appropriate for the region
4. Propose a practical implementation framework with clear phases and milestones
5. Address potential challenges and solutions for long-term sustainability
6. Incorporate indigenous knowledge and local practices where appropriate

Focus on creating holistic, community-driven approaches that restore ecosystem function while supporting local livelihoods and building ecological resilience."""
        }
    
    system_prompt = next((prompt for prompt in system_prompts.values() 
                         if isinstance(prompt, dict) and prompt.get("short_name") == short_name), None)
    if not system_prompt:
        available = ", ".join([f"'{p.get('short_name', 'UNKNOWN')}'" for p in system_prompts.values() 
                              if isinstance(p, dict) and "short_name" in p])
        error_msg = f"System prompt with short_name '{short_name}' not found. Available prompts: {available}"
        logger.warning(error_msg)
        # Instead of raising an error, we'll just use our default prompt
        return get_system_message(system_prompts, "ecological_regeneration_planner")
    
    return {
        "role": "system",
        "content": system_prompt["description"]
    }

def load_research_reports(region_dir):
    """Load all research reports from a region directory."""
    research_data = {}
    
    # Updated pattern to match the actual filenames generated by the research script
    # Look for files with persona names in them
    persona_keywords = ['ecological_researcher', 'human_intelligence_officer', 'dataset_specialist']
    found_personas = []
    missing_personas = []
    
    # First try to find the individual research files
    for persona in persona_keywords:
        md_files = glob.glob(os.path.join(region_dir, f"*{persona}*.md"))
        if md_files:
            try:
                with open(md_files[0], 'r', encoding='utf-8') as f:
                    content = f.read()
                    # Get simplified persona type
                    if 'ecological' in persona:
                        persona_type = 'ecological'
                    elif 'intelligence' in persona:
                        persona_type = 'stakeholders'
                    elif 'dataset' in persona:
                        persona_type = 'datasets'
                    else:
                        persona_type = persona
                    
                    research_data[persona_type] = content
                    found_personas.append(persona_type)
                    logger.info(f"Loaded research for {persona_type} from {os.path.basename(md_files[0])}")
            except FileNotFoundError:
                # File was found by glob but disappeared - this is unusual but not critical
                logger.info(f"⚠️ Research file for {persona} was found but then disappeared - skipping")
                missing_personas.append(persona)
            except Exception as e:
                # Only log as ERROR for unexpected file read errors, not for missing files
                logger.warning(f"⚠️ Error reading research file {md_files[0]}: {e} - continuing without this data")
        else:
            missing_personas.append(persona)
    
    # Log information about missing personas - this is not an error, it's INFO level
    if missing_personas:
        logger.info(f"ℹ️ Some personas are not available: {', '.join(missing_personas)} - continuing with existing data (expected behavior)")
    
    if found_personas:
        logger.info(f"✅ Successfully loaded research from {len(found_personas)} persona(s): {', '.join(found_personas)}")
    
    # If we couldn't find individual files, try to find consolidated research
    if not research_data:
        consolidated_files = glob.glob(os.path.join(region_dir, "*consolidated_research_*.md"))
        if consolidated_files:
            try:
                with open(consolidated_files[0], 'r', encoding='utf-8') as f:
                    content = f.read()
                    research_data['consolidated'] = content
                    logger.info(f"Loaded consolidated research from {os.path.basename(consolidated_files[0])}")
            except FileNotFoundError:
                # File was found by glob but disappeared - log as info, not error
                logger.info(f"⚠️ Consolidated research file was found but then disappeared - continuing without it")
            except Exception as e:
                # Use warning level for unexpected errors reading files
                logger.warning(f"⚠️ Error reading consolidated research file {consolidated_files[0]}: {e} - continuing without this data")
    
    return research_data

def generate_regeneration_prompt(bioregion, research_data):
    """Generate prompt for ecological regeneration project planning."""
    
    # Format the research data properly
    formatted_research = ""
    for persona_type, content in research_data.items():
        formatted_research += f"\n\n--- {persona_type.upper()} RESEARCH ---\n\n{content}\n"
    
    prompt = f"""Please analyze the following comprehensive research data for the {bioregion['name']} bioregion 
and develop a detailed ecological regeneration project plan that is place-based and community-driven.

The research includes multiple expert perspectives on the bioregion:
{formatted_research}

Based on this research, please provide a comprehensive ecological regeneration project plan that includes:

1. ECOLOGICAL ASSESSMENT & PRIORITIES
   * Key ecosystems and habitats requiring restoration or protection
   * Important plant and animal species to focus conservation efforts on
   * Critical ecological processes and functions to restore
   * Priority areas for immediate intervention

2. LOCAL STAKEHOLDERS & COMMUNITY ENGAGEMENT
   * Key local communities, indigenous groups, and stakeholders to involve
   * Specific organizations and experts identified in the research
   * Approaches for inclusive community participation
   * Integration of traditional ecological knowledge

3. REGENERATIVE ACTIVITIES & INTERVENTIONS
   * Specific ecological restoration techniques appropriate for this bioregion
   * Sustainable land management practices to implement
   * Species reintroduction or protection measures
   * Ecosystem connectivity and resilience building approaches

4. IMPLEMENTATION FRAMEWORK
   * Phased project timeline with clear milestones
   * Potential funding sources and resource requirements
   * Monitoring protocols to track ecological recovery
   * Governance structure for project management

5. CHALLENGES & ADAPTIVE MANAGEMENT
   * Potential barriers to implementation and how to address them
   * Climate change considerations and adaptation strategies
   * Socioeconomic factors that may impact success
   * Long-term sustainability and self-sufficiency plan

Please ensure your project plan is:
- Scientifically sound and based on the specific ecological conditions of this bioregion
- Culturally appropriate and respectful of local communities
- Practical and implementable with clear actionable steps
- Holistic in addressing both ecological and social dimensions of regeneration"""

    return prompt

def save_regeneration_plan(output_dir, bioregion_id, content):
    """Save ecological regeneration plan as both JSON and MD files."""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # Save as Markdown
    md_filename = f"{bioregion_id}_ecological_regeneration_plan_{timestamp}.md"
    md_path = os.path.join(output_dir, md_filename)
    
    # Use specific file logging operations for each file
    md_result = save_markdown_file(md_path, content)
    
    # Also save as structured JSON
    json_filename = f"{bioregion_id}_ecological_regeneration_plan_{timestamp}.json"
    json_path = os.path.join(output_dir, json_filename)
    
    json_result = save_json_file(json_path, {
        "content": content,
        "timestamp": timestamp,
        "bioregion_id": bioregion_id,
        "ecological_regeneration_plan": content
    })
    
    logger.info(f"Saved ecological regeneration plan for {bioregion_id}")
    return md_path

@log_file_operation
def save_markdown_file(file_path, content):
    """Save content to a markdown file."""
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    return file_path

@log_file_operation
def save_json_file(file_path, data):
    """Save data to a JSON file."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    return file_path

def extract_bioregion_info_from_path(path):
    """Extract bioregion information from directory path."""
    dir_name = os.path.basename(path)
    return {
        'name': dir_name.replace('_', ' '),
        '_id': dir_name  # Use directory name as ID if we don't have the real ID
    }

def get_perplexity_response(api_key, prompt, persona_description, model_name):
    """
    Get a response from the Perplexity API using the requests library
    """
    try:
        logging.debug(f"Making API call with model: {model_name}")
        logging.debug(f"Prompt: {prompt}")
        logging.debug(f"Persona: {persona_description}")
        
        # Create the API request payload
        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": persona_description},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 4096,
            "temperature": 0.7,
        }
        
        # Make the API request
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json=payload
        )
        
        # Check if the request was successful
        response.raise_for_status()
        
        # Parse the JSON response
        response_data = response.json()
        
        # Extract the content from the response
        return response_data["choices"][0]["message"]["content"]
        
    except requests.exceptions.HTTPError as e:
        # Handle HTTP errors that might be temporary (rate limits, server issues)
        logging.warning(f"⚠️ API HTTP error: {str(e)} - This might be temporary")
        return f"API HTTP error: {str(e)}. This might be temporary, retry may succeed."
    except requests.exceptions.ConnectionError as e:
        # Handle connection errors that might be temporary
        logging.warning(f"⚠️ API connection error: {str(e)} - Check network connection")
        return f"API connection error: {str(e)}. Check network connection."
    except Exception as e:
        # Keep ERROR level for unexpected issues
        logging.error(f"⚠️ Unexpected API error: {str(e)}")
        return f"Error making API call: {str(e)}"

def process_region_regeneration_plan(client, system_prompts, base_dir, region_dir, model_name):
    """Process ecological regeneration plan for a specific region."""
    # Extract bioregion info from directory name
    bioregion = extract_bioregion_info_from_path(region_dir)
    bioregion_id = bioregion.get('_id')
    
    if not os.path.exists(region_dir):
        logger.warning(f"No research data found for {bioregion_id}")
        return
    
    # Try to find a consolidated research file to get the real bioregion ID
    consolidated_files = glob.glob(os.path.join(region_dir, "*_consolidated_research_*.json"))
    if consolidated_files:
        try:
            with open(consolidated_files[0], 'r', encoding='utf-8') as f:
                data = json.load(f)
                # Get the first persona data to extract the bioregion ID
                if data and isinstance(data, dict) and len(data) > 0:
                    first_persona = next(iter(data.values()))
                    if 'bioregion_id' in first_persona:
                        bioregion_id = first_persona['bioregion_id']
                        bioregion['_id'] = bioregion_id
        except Exception as e:
            logger.warning(f"Error extracting bioregion ID from consolidated file: {e}")
    
    # Load all research reports
    research_data = load_research_reports(region_dir)
    if not research_data:
        logger.warning(f"No research reports found for {bioregion_id}")
        return
    
    # Log the number of personas found
    logger.info(f"Generating regeneration plan for {bioregion_id} with data from {len(research_data)} persona(s)")
    
    # Generate regeneration plan prompt
    prompt = generate_regeneration_prompt(bioregion, research_data)
    
    messages = [
        get_system_message(system_prompts, TARGET_SYSTEM_PROMPT),
        {"role": "user", "content": prompt}
    ]
    
    logger.info(f"Generating ecological regeneration plan for {bioregion_id}")
    start_time = time.time()
    
    try:
        logger.info(f"Using Perplexity model: {model_name}")
        response = get_perplexity_response(client, prompt, get_system_message(system_prompts, TARGET_SYSTEM_PROMPT)["content"], model_name)
        
        # Check if response indicates an error occurred
        if response.startswith("Error making API call") or response.startswith("API HTTP error") or response.startswith("API connection error"):
            logger.warning(f"⚠️ Could not generate regeneration plan for {bioregion_id} due to API issues: {response}")
            return
            
        # Save the regeneration plan
        output_path = save_regeneration_plan(region_dir, bioregion_id, response)
        
        elapsed_time = time.time() - start_time
        logger.info(f"Ecological regeneration plan generated successfully in {elapsed_time:.2f} seconds")
        logger.info(f"Saved to: {output_path}")
        
    except Exception as e:
        # Only use ERROR for unexpected exceptions, not for known API issues
        logger.error(f"❌ Unexpected error generating ecological regeneration plan for {bioregion_id}: {e}")
        # Don't raise the exception - just log and continue with next bioregion
        return
    
    # Rate limiting
    time.sleep(2)

def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Generate ecological regeneration plans for bioregions")
    parser.add_argument("--model", choices=["testing", "production"], default="testing",
                       help="Model to use: 'testing' (cheaper) or 'production' (better results)")
    args = parser.parse_args()
    
    logger = setup_logging()
    
    # Setup paths and load required data
    script_dir = os.path.dirname(os.path.abspath(__file__))
    key_file_path = os.path.join(script_dir, "OneEarth_Perplexity_keys.key")
    
    try:
        # Initialize API client
        perplexity_api_key = load_api_key(key_file_path)
        client = perplexity_api_key
        
        # Load system prompts file
        system_prompts = load_json_file(os.path.join(script_dir, 'OneEarth_System_Prompts.json'))
        
        # Get model configuration
        model_config = args.model  # "testing" or "production"
        model_name = system_prompts.get("config", {}).get("models", {}).get(model_config, "sonar")
        logger.info(f"Using Perplexity model: {model_name} ({model_config} mode)")
        
        # Process each bioregion folder in the Outputs directory
        outputs_dir = os.path.join(script_dir, 'Outputs')
        
        if not os.path.exists(outputs_dir):
            logger.error(f"Outputs directory not found: {outputs_dir}")
            return
        
        region_dirs = [d for d in os.listdir(outputs_dir) 
                      if os.path.isdir(os.path.join(outputs_dir, d))]
        
        if not region_dirs:
            logger.warning("No region directories found in Outputs folder")
            return
        
        # Create a mapping of normalized region names to their directory paths
        # This helps handle the transition from mixed naming conventions to a consistent one
        normalized_regions = {}
        for region_dir_name in region_dirs:
            # Normalize the name by removing underscores and spaces
            base_name = region_dir_name.replace('_', ' ')
            # Then consistently convert to the new format (spaces to underscores)
            normalized_name = base_name.replace(' ', '_').replace('/', '_')
            
            # If we already have this region with a different naming format,
            # merge by keeping the normalized (underscored) version
            if normalized_name in normalized_regions:
                # If both versions exist, prefer the normalized version
                current_path = normalized_regions[normalized_name]
                if region_dir_name == normalized_name:
                    normalized_regions[normalized_name] = os.path.join(outputs_dir, region_dir_name)
            else:
                normalized_regions[normalized_name] = os.path.join(outputs_dir, region_dir_name)
        
        # Now process each normalized region
        for i, (normalized_name, region_dir) in enumerate(normalized_regions.items()):
            region_count = i + 1
            total_regions = len(normalized_regions)
            
            logger.info(f"\nProcessing region {region_count}/{total_regions}: {normalized_name}")
            
            try:
                process_region_regeneration_plan(client, system_prompts, outputs_dir, region_dir, model_name)
                logger.info(f"✅ Completed ecological regeneration plan for region {normalized_name}")
            except Exception as e:
                # This shouldn't happen since we catch exceptions in process_region_regeneration_plan
                # But just in case, log as warning and continue with next region
                logger.warning(f"⚠️ Issue processing region {normalized_name}: {str(e)} - continuing with next region")
        
        logger.info("All ecological regeneration plans completed")
        
    except Exception as e:
        # Only use ERROR for fatal issues that prevent the entire process from working
        logger.error(f"❌ Fatal error in main process: {e}")
        # Don't raise - log the error and exit gracefully
        return

if __name__ == "__main__":
    main() 